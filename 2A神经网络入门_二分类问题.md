# 电影评论分类 —— 二分类问题
将数据集中的电影评论的文字内容分类为正面或负面

#### IMDB数据集
    含有训练用的25000条评论以及测试用的25000条评论
    这与MNIST数据集一样内置在keras库中

#### 代码
    首先，如下面代码所示，通过keras的库来将IMDB数据集导入
    并放入变量中，再把变量的数据处理成为张量
    有以下两种转换方法
    1. 将列表填充至相同长度
        在转换为(samples, features)的形状
    2. 使用one-hot编码
        转换为0、1组成的向量

>例：序列[3,5]转换为10000维向量，只有索引为3、5的元素为1，其余为0

`from keras.datasets import imdb`
`(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)`

    在这个网络中输入为向量，标签为标量，这可能是最简单的情况了
    面对这种问题，带有relu激活的全连接层的简单堆叠会很有效
    比如 ' Dense(16, activation='relu') '
    这段中的参数16就是该层隐藏单元的个数
    也就是表示空间的一个维度，越多维度就能学到更加复杂的表示
    但是这会让网络的计算代价会越高、也有可能直接学不好
    （能让训练数据的性能提高，但是测试数据无法提高）

dense层的堆叠需要确定以下两点
1. 网络的层数
2. 每层的隐藏单元
>对于这个问题，书中给出了下面的架构
    1. 两个中间层，每层16个隐藏单元
    2. 第三层输出一个标量预测情
    中间层使用relu作为中间层的激活函数，在最后一层用sigmoid激活
    输出0~1的范围内的概率值

`model = model.Sequential()`
`model.add(layers.Dense(16, activation='relu', inpur_shape=(10000, )))`
`model.add(layers.Dense(16, activation='relu'))`
`model.add(layers.Dense(1, activation='sigmoid'))`

| relu(整流线性单元) | sigmoid |
|----|----|
|将所有负值归零|将任意值压缩到[0, 1]|

    然后就可以编译模型了，这里用的是
    rmsprop优化器、binary_crossentropy损失函数
    这两个都是在keras中内置好的，所以可以用字符串
    如果有需要，可以自己配置时优化器
    需要向模型的optimizer参数传入一个优化器类实例

`model.compile(optimizer='rmsprop',
            loss='binary_crossentropy',
            aetrics=['accuracy'],
            metrics=['acc'])`

    通过最后一个参数设定，在使用fit方法后会返回一个对象
    这个history对象含有下面四个值用以监控或plot作图
    ['loss', 'acc', 'val_loss', 'val_acc']
    分别为损失、精度、验证损失、验证精度，图像见下
    另外，可以从图中看出：
        随着训练的增加训练时的损失和精度越来越优秀
        但是验证精度则不然，这种现象被称为过拟合
        为了防止这种过拟合出现的方法有很多，比如减少训练次数
        对于这个例子而言，4次的训练就可以达到比较优秀的精度

![loss 图像](https://github.com/murasaki2004/keras_note/blob/main/images/2A_T%26Vloss.png)
![acc 图像](https://github.com/murasaki2004/keras_note/blob/main/images/2A_T%26Vacc.png)

### 一个网络的编写过程
    对原始数据预先处理成张量，可以采用多种编码格式
    使用relu激活的Dense层堆叠，可以解决多种问题，也许是最常用的
    对于二分类问题，最后的层应是只有一单元的sigmoid激活Dense层
    由此来将输出的值规定到0~1，另外，一般来说sigmoid就采用
    binary_crossentropy的损失函数就好。
    对于绝大部分问题，rmsprop优化器都是最好的。
    还有，模型并不会随着训练的次数而不断优化，在一定次数后会产生
    过拟合，尽管在训练数据上确实会更好，但是在测试数据上则会下跌
    一定要在训练时也关注测试数据的表现