# 电影评论分类 —— 二分类问题
将数据集中的电影评论的文字内容分类为正面或负面

#### IMDB数据集
    含有训练用的25000条评论以及测试用的25000条评论
    这与MNIST数据集一样内置在keras库中

#### 代码
    首先，如下面代码所示，通过keras的库来将IMDB数据集导入
    并放入变量中，再把变量的数据处理成为张量
    有以下两种转换方法
    1. 将列表填充至相同长度
        在转换为(samples, features)的形状
    2. 使用one-hot编码
        转换为0、1组成的向量

>例：序列[3,5]转换为10000维向量，只有索引为3、5的元素为1，其余为0

`from keras.datasets import imdb`
`(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)`

    在这个网络中输入为向量，标签为标量，这可能是最简单的情况了
    面对这种问题，带有relu激活的全连接层的简单堆叠会很有效
    比如 ' Dense(16, activation='relu') '
    这段中的参数16就是该层隐藏单元的个数
    也就是表示空间的一个维度，越多维度就能学到更加复杂的表示
    但是这会让网络的计算代价会越高、也有可能直接学不好
    （能让训练数据的性能提高，但是测试数据无法提高）

dense层的堆叠需要确定以下两点
1. 网络的层数
2. 每层的隐藏单元
>对于这个问题，书中给出了下面的架构
    1. 两个中间层，每层16个隐藏单元
    2. 第三层输出一个标量预测情
    中间层使用relu作为中间层的激活函数，在最后一层用sigmoid激活
    输出0~1的范围内的概率值

`model = model.Sequential()`
`model.add(layers.Dense(16, activation='relu', inpur_shape=(10000, )))`
`model.add(layers.Dense(16, activation='relu'))`
`model.add(layers.Dense(1, activation='sigmoid'))`

| relu(整流线性单元) | sigmoid |
|----|----|
|将所有负值归零|将任意值压缩到[0, 1]|

    然后就可以编译模型了，这里用的是
    rmsprop优化器、binary_crossentropy损失函数
    这两个都是在keras中内置好的，所以可以用字符串
    如果有需要，可以自己配置时优化器
    需要向模型的optimizer参数传入一个优化器类实例

`model.compile(optimizer='rmsprop',
            loss='binary_crossentropy',
            aetrics=['accuracy'],
            metrics=['acc'])`

    通过最后一个参数设定，在使用fit方法后会返回一个对象
    这个history对象含有下面四个值用以监控或plot作图
    ['loss', 'acc', 'val_loss', 'val_acc']
    分别为损失、精度、验证损失、验证精度，图像见下
    另外，可以从图中看出：
        随着训练的增加训练时的损失和精度越来越优秀
        但是验证精度则不然，这种现象被称为过拟合

![loss 图像](https://github.com/murasaki2004/keras_note/blob/main/images/2A_T%26Vloss.png)
![acc 图像](https://github.com/murasaki2004/keras_note/blob/main/images/2A_T%26Vacc.png)